{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 13:20:34.200 INFO    numexpr.utils: Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-04-24 13:20:34.201 INFO    numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing, metrics, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "import pycaret.classification as pc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/04/24 13:24:15 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2022/04/24 13:24:15 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "# Criando experimento e fazendo tracking com SQLite\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///runs_mlflow.db\")\n",
    "experiment_name = 'Projeto - Engenharia de Machine Learning'\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "experiment_id = experiment.experiment_id\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coleta e preparação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Bases de Dados ==\n",
      "Dataset de treino (16228, 7)\n",
      "Dataset de teste (4057, 7)\n",
      "Colunas: ['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id, run_name='PreparacaoDados', nested=True):\n",
    "\n",
    "    # Colunas usadas no modelo\n",
    "    features = ['lat', 'lon', 'minutes_remaining',\n",
    "                'period', 'playoffs', 'shot_distance']\n",
    "    \n",
    "    target = 'shot_made_flag'\n",
    "    \n",
    "    \n",
    "    # Leitura dos dados\n",
    "    df = pd.read_csv('./Data/kobe_dataset.csv')\n",
    "    df.dropna(subset=[target], inplace=True)\n",
    "    \n",
    "    \n",
    "    # Separando dataset de treino e de operação\n",
    "    \n",
    "        # Percentual separado para teste\n",
    "    test_size = 0.2\n",
    "    \n",
    "        # Modelo (treino + teste)\n",
    "    data_filtered = df.query('shot_type == \"2PT Field Goal\"')[features + [target]].copy()\n",
    "    data_operation = df.query('shot_type == \"3PT Field Goal\"')[features + [target]].copy()\n",
    "    data_filtered.to_parquet('./Data/processed/data_filtered.parquet')\n",
    "    data_operation.to_parquet('./Data/processed/data_operation.parquet')\n",
    "       \n",
    "    data_train, data_test, y_train, y_test = train_test_split(data_filtered[features],\n",
    "                                                              data_filtered[[target]],\n",
    "                                                              test_size=test_size, \n",
    "                                                              stratify=data_filtered[[target]])\n",
    "    \n",
    "    data_train[target] = y_train\n",
    "    data_test[target] = y_test\n",
    "      \n",
    "    data_train.to_parquet('./Data/operalization/base_train.parquet')\n",
    "    data_test.to_parquet('./Data/operalization/base_test.parquet')\n",
    "    \n",
    "    \n",
    "    # Log de parâmetro do modelo\n",
    "    mlflow.log_param('Test Size', test_size)\n",
    "\n",
    "    # Log de métricas globais\n",
    "    mlflow.log_metric('Dataset de treino - Tamanho', data_train.shape[0])\n",
    "    mlflow.log_metric('Dataset de teste - Tamanho', data_test.shape[0])\n",
    "   \n",
    "    \n",
    "mlflow.end_run()\n",
    "\n",
    "print('== Bases de Dados ==')\n",
    "print(f'Dataset de treino {data_train.shape}')\n",
    "print(f'Dataset de teste {data_test.shape}')\n",
    "print(f'Colunas: {list(data_train.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  [logs] Saving 'Learning Curve.png'\n",
      "INFO  [logs] Visual Rendered Successfully\n",
      "INFO  [logs] plot_model() succesfully completed......................................\n",
      "INFO  [logs] Initializing save_model()\n",
      "INFO  [logs] save_model(model=LogisticRegression(C=7.689, class_weight={}, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False), model_name=./modelo_kobe, prep_pipe_=Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=['playoffs'],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=['lat', 'lon',\n",
      "                                                          'minutes_remaining',\n",
      "                                                          'shot_distance',\n",
      "                                                          'period'],\n",
      "                                      target='shot_made_flag',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_ava...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='shot_made_flag')),\n",
      "                ('fix_perfect', Remove_100(target='shot_made_flag')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False), verbose=True, kwargs={})\n",
      "INFO  [logs] Adding model into prep_pipe\n",
      "INFO  [logs] ./modelo_kobe.pkl saved in current working directory\n",
      "INFO  [logs] Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=['playoffs'],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=['lat', 'lon',\n",
      "                                                          'minutes_remaining',\n",
      "                                                          'shot_distance',\n",
      "                                                          'period'],\n",
      "                                      target='shot_made_flag',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_ava...\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough'),\n",
      "                ['trained_model',\n",
      "                 LogisticRegression(C=7.689, class_weight={}, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=1000,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=123,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False)]],\n",
      "         verbose=False)\n",
      "INFO  [logs] save_model() successfully completed......................................\n",
      "INFO  [logs] Initializing save_model()\n",
      "INFO  [logs] save_model(model=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,\n",
      "                                     classifier=LogisticRegression(C=1.0,\n",
      "                                                                   class_weight=None,\n",
      "                                                                   dual=False,\n",
      "                                                                   fit_intercept=True,\n",
      "                                                                   intercept_scaling=1,\n",
      "                                                                   l1_ratio=None,\n",
      "                                                                   max_iter=1000,\n",
      "                                                                   multi_class='auto',\n",
      "                                                                   n_jobs=None,\n",
      "                                                                   penalty='l2',\n",
      "                                                                   random_state=123,\n",
      "                                                                   solver='lbfgs',\n",
      "                                                                   tol=0.0001,\n",
      "                                                                   verbose=0,\n",
      "                                                                   warm_start=False),\n",
      "                                     dual=False, fit_intercept=True,\n",
      "                                     intercept_scaling=1, l1_ratio=None,\n",
      "                                     max_iter=1000, multi_class='auto',\n",
      "                                     n_jobs=None, penalty='l2',\n",
      "                                     probability_threshold=0.5,\n",
      "                                     random_state=123, solver='lbfgs',\n",
      "                                     tol=0.0001, verbose=0, warm_start=False), model_name=./modelo_kobe_reglog, prep_pipe_=Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=['playoffs'],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=['lat', 'lon',\n",
      "                                                          'minutes_remaining',\n",
      "                                                          'shot_distance',\n",
      "                                                          'period'],\n",
      "                                      target='shot_made_flag',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_ava...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='shot_made_flag')),\n",
      "                ('fix_perfect', Remove_100(target='shot_made_flag')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False), verbose=True, kwargs={})\n",
      "INFO  [logs] Adding model into prep_pipe\n",
      "INFO  [logs] ./modelo_kobe_reglog.pkl saved in current working directory\n",
      "INFO  [logs] Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=['playoffs'],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=['lat', 'lon',\n",
      "                                                          'minutes_remaining',\n",
      "                                                          'shot_distance',\n",
      "                                                          'period'],\n",
      "                                      target='shot_made_flag',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_ava...\n",
      "                                                                                    multi_class='auto',\n",
      "                                                                                    n_jobs=None,\n",
      "                                                                                    penalty='l2',\n",
      "                                                                                    random_state=123,\n",
      "                                                                                    solver='lbfgs',\n",
      "                                                                                    tol=0.0001,\n",
      "                                                                                    verbose=0,\n",
      "                                                                                    warm_start=False),\n",
      "                                                      dual=False,\n",
      "                                                      fit_intercept=True,\n",
      "                                                      intercept_scaling=1,\n",
      "                                                      l1_ratio=None,\n",
      "                                                      max_iter=1000,\n",
      "                                                      multi_class='auto',\n",
      "                                                      n_jobs=None, penalty='l2',\n",
      "                                                      probability_threshold=0.5,\n",
      "                                                      random_state=123,\n",
      "                                                      solver='lbfgs',\n",
      "                                                      tol=0.0001, verbose=0,\n",
      "                                                      warm_start=False)]],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  [logs] save_model() successfully completed......................................\n",
      "INFO  [logs] Initializing load_model()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n",
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  [logs] load_model(model_name=./modelo_kobe, platform=None, authentication=None, verbose=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'modelo_kobe' already exists. Creating a new version of this model...\n",
      "2022/04/24 13:26:56 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: modelo_kobe, version 2\n",
      "Created version '2' of model 'modelo_kobe'.\n"
     ]
    }
   ],
   "source": [
    "registered_model_name = 'modelo_kobe'\n",
    "model_test = 'modelo_kobe_reglog'\n",
    "model_version = -1\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name='Treinamento', nested=True):\n",
    "    \n",
    "    pc.setup(session_id=123,\n",
    "             data = data_train, \n",
    "             train_size=1-test_size,\n",
    "             target = 'shot_made_flag',\n",
    "             fold_strategy = 'stratifiedkfold', \n",
    "             fold = 10,\n",
    "             categorical_features = ['playoffs'],\n",
    "             numeric_features = ['lat', 'lon', 'minutes_remaining', 'shot_distance', 'period'], \n",
    "             experiment_name = experiment_name,\n",
    "             silent=True)\n",
    "    \n",
    "    model_lr = pc.create_model(estimator='lr', probability_threshold=0.5)\n",
    "    \n",
    "    # Dummies do x_test (o pycaret automaticamente dropou playoffs_1 no treinamento)\n",
    "    x_test_dum = pd.get_dummies(data_test, columns=['playoffs']).drop(['shot_made_flag',\n",
    "                                                                       'playoffs_1'], \n",
    "                                                                      axis=1)\n",
    "    \n",
    "    # Registrar log_loss com base de teste\n",
    "    y_true = data_test.shot_made_flag.values\n",
    "    y_pred_lr = model_lr.predict(x_test_dum.values)\n",
    "    \n",
    "    lr_log_loss = log_loss(y_true, y_pred_lr)\n",
    "    \n",
    "    mlflow.log_metric('Log Loss - Logistic Regression', lr_log_loss)\n",
    "    \n",
    "    best_model = pc.compare_models(n_select = 1, sort='Accuracy', include=['lr', 'dt', 'svm'])\n",
    "    \n",
    "    tuned_model = pc.tune_model(best_model,\n",
    "                                optimize = 'Accuracy',\n",
    "                                search_library = 'scikit-learn',\n",
    "                                search_algorithm = 'random',\n",
    "                                n_iter = 4)\n",
    "    \n",
    "    y_pred_tuned_model = tuned_model.predict(x_test_dum.values)\n",
    "    \n",
    "    # Registrar log_loss e f1_ratio com base de teste\n",
    "    tuned_log_loss = log_loss(y_true, y_pred_tuned_model)\n",
    "    tuned_f1 = f1_score(y_true, y_pred_tuned_model)\n",
    "    \n",
    "    mlflow.log_metric('Log Loss - Tuned Model', tuned_log_loss)\n",
    "    mlflow.log_metric('F1 Score - Tuned Model', tuned_f1)\n",
    "    \n",
    "    # Artefatos utilizados\n",
    "    classification_plots = ['auc', 'threshold', 'pr', \n",
    "                            'confusion_matrix', 'class_report', 'feature', 'learning']\n",
    "\n",
    "    for plot_type in classification_plots:\n",
    "        print('=> Aplicando plot ', plot_type)\n",
    "        try:\n",
    "            artifact = pc.plot_model(tuned_model, plot=plot_type, save=True, use_train_data=False)\n",
    "            mlflow.log_artifact(artifact)\n",
    "        except:\n",
    "            print('=> Nao possível plotar: ', plot_type)\n",
    "            continue\n",
    "\n",
    "    pc.save_model(tuned_model, f'./{registered_model_name}') \n",
    "    pc.save_model(model_lr, f'./{model_test}')\n",
    "    # Carrega novamente o pipeline + modelo tunado\n",
    "    model_pipe = pc.load_model(f'./{registered_model_name}')\n",
    "\n",
    "    \n",
    "    # -------------- Registro -------------------\n",
    "    \n",
    "    # Assinatura do Modelo Inferida pelo MLFlow\n",
    "    \n",
    "    model_features = list(data_test.columns)\n",
    "    inf_signature = infer_signature(data_filtered, model_pipe.predict(data_test))\n",
    "    \n",
    "    # Exemplo de entrada para o MLmodel\n",
    "    input_example = {x: data_test[x].values[:5] for x in features}\n",
    "    \n",
    "    # Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "    mlflow.sklearn.log_model(sk_model=model_pipe,\n",
    "                             artifact_path=\"sklearn-model\",\n",
    "                             registered_model_name=registered_model_name,\n",
    "                             signature = inf_signature,\n",
    "                             input_example = input_example)\n",
    "    \n",
    "    # Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "    client = MlflowClient()\n",
    "    if model_version == -1:\n",
    "        model_version = client.get_latest_versions(registered_model_name)[-1].version\n",
    "    \n",
    "    # Registrar o modelo como staging\n",
    "    client.transition_model_version_stage(name=registered_model_name,\n",
    "                                          version=model_version, \n",
    "                                          stage=\"Staging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Servindo o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.66      0.62      2120\n",
      "         1.0       0.57      0.50      0.54      1937\n",
      "\n",
      "    accuracy                           0.58      4057\n",
      "   macro avg       0.58      0.58      0.58      4057\n",
      "weighted avg       0.58      0.58      0.58      4057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "host = 'localhost'\n",
    "port = '5001'\n",
    "url = f'http://{host}:{port}/invocations'\n",
    "headers = {'Content-Type': 'application/json',}\n",
    "\n",
    "http_data = data_test.to_json(orient='split')\n",
    "r = requests.post(url=url, headers=headers, data=http_data)\n",
    "\n",
    "data_test.loc[:, 'operation_label'] = pd.read_json(r.text).values[:,0]\n",
    "\n",
    "print(metrics.classification_report(data_test['shot_made_flag'], data_test['operation_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80      3630\n",
      "         1.0       0.00      0.00      0.00      1782\n",
      "\n",
      "    accuracy                           0.67      5412\n",
      "   macro avg       0.34      0.50      0.40      5412\n",
      "weighted avg       0.45      0.67      0.54      5412\n",
      "\n",
      "Log Loss: 11.38\n",
      "F1-Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "host = 'localhost'\n",
    "port = '5001'\n",
    "url = f'http://{host}:{port}/invocations'\n",
    "headers = {'Content-Type': 'application/json',}\n",
    "\n",
    "data_3_pts = df.query('shot_type == \"3PT Field Goal\"')[features + [target]].copy()\n",
    "\n",
    "http_data = data_3_pts.to_json(orient='split')\n",
    "r = requests.post(url=url, headers=headers, data=http_data)\n",
    "\n",
    "data_3_pts.loc[:, 'operation_label'] = pd.read_json(r.text).values[:,0]\n",
    "\n",
    "print(metrics.classification_report(data_3_pts['shot_made_flag'], data_3_pts['operation_label']))\n",
    "print('Log Loss: {:.2f}' .format(log_loss(data_3_pts['shot_made_flag'], data_3_pts['operation_label'])))\n",
    "print('F1-Score: {:.2f}' .format(f1_score(data_3_pts['shot_made_flag'], data_3_pts['operation_label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
